{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%202%20-%20Custom%20Training%20loops%2C%20Gradients%20and%20Distributed%20Training/Week%204%20-%20Distribution%20Strategy/C2_W4_Lab_1_basic-mirrored-strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirrored Strategy: Basic\n",
    "\n",
    "In this ungraded lab, you'll go through some of the basics of applying [Mirrored Strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkUjfmKkflCd"
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow and TensorFlow Datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset and split it into training and test chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQN-PtIGgFtH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ./data\\mnist\\3.0.1...\u001b[0m\n",
      "\u001b[1mDataset mnist downloaded and prepared to ./data\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset we'll use for this lab\n",
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='./data')\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you define `strategy` using the `MirroredStrategy()` class. Print to see the number of devices available.\n",
    "\n",
    "**Note:** \n",
    "- If you are running this on Coursera, you'll see it gives a warning about no presence of GPU devices. \n",
    "- If you are running this in Colab, make sure you have selected your `Runtime` to be `GPU` for it to detect it. \n",
    "- In both these cases, you'll see there's only 1 device that is available.  \n",
    "- One device is sufficient for helping you understand these distribution strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCsDqWnDgNHr"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Multiple OpKernel registrations match NodeDef at the same priority '{{node AssignVariableOp}}': 'op: \"AssignVariableOp\" device_type: \"GPU\" constraint { name: \"dtype\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"resource\"' and 'op: \"AssignVariableOp\" device_type: \"GPU\" constraint { name: \"dtype\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"resource\"'\n\t [[AssignVariableOp]] [Op:AssignVariableOp]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the strategy to use and print the number of devices found\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m strategy \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMirroredStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of devices: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(strategy\u001b[38;5;241m.\u001b[39mnum_replicas_in_sync))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py:286\u001b[0m, in \u001b[0;36mMirroredStrategy.__init__\u001b[1;34m(self, devices, cross_device_ops)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cross_device_ops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 286\u001b[0m   extended \u001b[38;5;241m=\u001b[39m \u001b[43mMirroredExtended\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_device_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_device_ops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m   \u001b[38;5;28msuper\u001b[39m(MirroredStrategy, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(extended)\n\u001b[0;32m    289\u001b[0m   distribute_lib\u001b[38;5;241m.\u001b[39mdistribution_strategy_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\n\u001b[0;32m    290\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMirroredStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py:342\u001b[0m, in \u001b[0;36mMirroredExtended.__init__\u001b[1;34m(self, container_strategy, devices, cross_device_ops)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collective_key_base \u001b[38;5;241m=\u001b[39m container_strategy\u001b[38;5;241m.\u001b[39m_collective_key_base\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communication_options \u001b[38;5;241m=\u001b[39m collective_util\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[0;32m    341\u001b[0m     implementation\u001b[38;5;241m=\u001b[39mcollective_util\u001b[38;5;241m.\u001b[39mCommunicationImplementation\u001b[38;5;241m.\u001b[39mNCCL)\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# TODO(b/128995245): Enable last partial batch support in graph mode.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py:367\u001b[0m, in \u001b[0;36mMirroredExtended._initialize_strategy\u001b[1;34m(self, devices)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_device_list_single_worker(devices):\n\u001b[0;32m    366\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_single_worker(devices)\n\u001b[1;32m--> 367\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collective_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_collective_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefer_collective_ops \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    369\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross_device_ops, cross_device_ops_lib\u001b[38;5;241m.\u001b[39mNcclAllReduce)\n\u001b[0;32m    370\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_cross_device_ops,\n\u001b[0;32m    371\u001b[0m                     cross_device_ops_lib\u001b[38;5;241m.\u001b[39mNcclAllReduce)):\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collective_ops_in_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py:381\u001b[0m, in \u001b[0;36mMirroredExtended._make_collective_ops\u001b[1;34m(self, devices)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_collective_ops\u001b[39m(\u001b[38;5;28mself\u001b[39m, devices):\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collective_keys \u001b[38;5;241m=\u001b[39m cross_device_utils\u001b[38;5;241m.\u001b[39mCollectiveKeys(\n\u001b[0;32m    380\u001b[0m       group_key_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collective_key_base)\n\u001b[1;32m--> 381\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcross_device_ops_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCollectiveAllReduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_devices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_devices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communication_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollective_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collective_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:1099\u001b[0m, in \u001b[0;36mCollectiveAllReduce.__init__\u001b[1;34m(self, devices, group_size, options, collective_keys, canonicalize_devices)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limited_nccl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices:\n\u001b[1;32m-> 1099\u001b[0m   launcher \u001b[38;5;241m=\u001b[39m \u001b[43mcross_device_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCollectiveReplicaLauncher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgroup_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collective_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_launchers\u001b[38;5;241m.\u001b[39mappend(launcher)\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m launcher\u001b[38;5;241m.\u001b[39mcan_order_nccl():\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:271\u001b[0m, in \u001b[0;36mCollectiveReplicaLauncher.__init__\u001b[1;34m(self, group_key, group_size, collective_keys, device, options)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ordering_token():\n\u001b[0;32m    270\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minit_scope(), ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ordering_token \u001b[38;5;241m=\u001b[39m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ordering_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\directml_tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Multiple OpKernel registrations match NodeDef at the same priority '{{node AssignVariableOp}}': 'op: \"AssignVariableOp\" device_type: \"GPU\" constraint { name: \"dtype\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"resource\"' and 'op: \"AssignVariableOp\" device_type: \"GPU\" constraint { name: \"dtype\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"resource\"'\n\t [[AssignVariableOp]] [Op:AssignVariableOp]"
     ]
    }
   ],
   "source": [
    "# Define the strategy to use and print the number of devices found\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you create your training and test examples, define your batch size and also define `BATCH_SIZE_PER_REPLICA` which is the distribution you are making for each available device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1xWxKcnhar9"
   },
   "outputs": [],
   "source": [
    "# Get the number of examples in the train and test sets\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "# Use for Mirrored Strategy\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "# Use for No Strategy\n",
    "# BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mapping function which normalizes your images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPIU8E7BhyYq"
   },
   "outputs": [],
   "source": [
    "# Function for normalizing the image\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you create your training and evaluation datesets in the batch size you want by shuffling through your buffer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByTZB2AYh0nA"
   },
   "outputs": [],
   "source": [
    "# Set up the train and eval data set\n",
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your model to follow the strategy, define your model within the strategy's scope.\n",
    "- Run all the cells below and notice the results. \n",
    "- Afterwards comment out `with strategy.scope():` and run everything again, without the strategy. \n",
    "Then you can compare the results. \n",
    "The important thing to notice and compare is the time taken for each epoch to complete. As mentioned in the lecture, doing a mirrored strategy on a single device (which our lab environment has) might take longer to train because of the overhead in implementing the strategy. With that, the advantages of using this strategy is more evident if you will use it on multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rRzY5ojh51B"
   },
   "outputs": [],
   "source": [
    "# Use for Mirrored Strategy -- comment out `with strategy.scope():` and deindent for no strategy\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWOJWLENphod"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8voqkush_Bx"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=12)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Basic Mirrored Strategy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
